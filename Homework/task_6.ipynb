{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Провести сравнение RNN, LSTM, GRU на датасете отзывов (из предыдущих занятий/материалов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>tweet_token_filtered</th>\n",
       "      <th>tweet_stemmed</th>\n",
       "      <th>tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when fatheare is dysfyounctional and is so sel...</td>\n",
       "      <td>['when', 'fatheare', 'is', 'dysfyounctional', ...</td>\n",
       "      <td>['fatheare', 'dysfyounctional', 'selfish', 'da...</td>\n",
       "      <td>['fathear', 'dysfyounct', 'selfish', 'dareagar...</td>\n",
       "      <td>['fatheare', 'dysfyounctional', 'selfish', 'da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks foare lyft careedit cannot youse cayous...</td>\n",
       "      <td>['thanks', 'foare', 'lyft', 'careedit', 'can',...</td>\n",
       "      <td>['thanks', 'foare', 'lyft', 'careedit', 'youse...</td>\n",
       "      <td>['thank', 'foar', 'lyft', 'careedit', 'yous', ...</td>\n",
       "      <td>['thank', 'foare', 'lyft', 'careedit', 'youse'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday yoyouare majesty</td>\n",
       "      <td>['bihday', 'yoyouare', 'majesty']</td>\n",
       "      <td>['bihday', 'yoyouare', 'majesty']</td>\n",
       "      <td>['bihday', 'yoyouar', 'majesti']</td>\n",
       "      <td>['bihday', 'yoyouare', 'majesty']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model love you take with you all the time in y...</td>\n",
       "      <td>['model', 'love', 'you', 'take', 'with', 'you'...</td>\n",
       "      <td>['model', 'love', 'take', 'time', 'youare']</td>\n",
       "      <td>['model', 'love', 'take', 'time', 'youar']</td>\n",
       "      <td>['model', 'love', 'take', 'time', 'youare']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsgareinyouide society now motivation</td>\n",
       "      <td>['factsgareinyouide', 'society', 'now', 'motiv...</td>\n",
       "      <td>['factsgareinyouide', 'society', 'motivation']</td>\n",
       "      <td>['factsgareinyouid', 'societi', 'motiv']</td>\n",
       "      <td>['factsgareinyouide', 'society', 'motivation']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1    0.0   @user when a father is dysfunctional and is s...   \n",
       "1   2    0.0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3    0.0                                bihday your majesty   \n",
       "3   4    0.0  #model   i love u take with u all the time in ...   \n",
       "4   5    0.0             factsguide: society now    #motivation   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  when fatheare is dysfyounctional and is so sel...   \n",
       "1  thanks foare lyft careedit cannot youse cayous...   \n",
       "2                            bihday yoyouare majesty   \n",
       "3  model love you take with you all the time in y...   \n",
       "4           factsgareinyouide society now motivation   \n",
       "\n",
       "                                         tweet_token  \\\n",
       "0  ['when', 'fatheare', 'is', 'dysfyounctional', ...   \n",
       "1  ['thanks', 'foare', 'lyft', 'careedit', 'can',...   \n",
       "2                  ['bihday', 'yoyouare', 'majesty']   \n",
       "3  ['model', 'love', 'you', 'take', 'with', 'you'...   \n",
       "4  ['factsgareinyouide', 'society', 'now', 'motiv...   \n",
       "\n",
       "                                tweet_token_filtered  \\\n",
       "0  ['fatheare', 'dysfyounctional', 'selfish', 'da...   \n",
       "1  ['thanks', 'foare', 'lyft', 'careedit', 'youse...   \n",
       "2                  ['bihday', 'yoyouare', 'majesty']   \n",
       "3        ['model', 'love', 'take', 'time', 'youare']   \n",
       "4     ['factsgareinyouide', 'society', 'motivation']   \n",
       "\n",
       "                                       tweet_stemmed  \\\n",
       "0  ['fathear', 'dysfyounct', 'selfish', 'dareagar...   \n",
       "1  ['thank', 'foar', 'lyft', 'careedit', 'yous', ...   \n",
       "2                   ['bihday', 'yoyouar', 'majesti']   \n",
       "3         ['model', 'love', 'take', 'time', 'youar']   \n",
       "4           ['factsgareinyouid', 'societi', 'motiv']   \n",
       "\n",
       "                                    tweet_lemmatized  \n",
       "0  ['fatheare', 'dysfyounctional', 'selfish', 'da...  \n",
       "1  ['thank', 'foare', 'lyft', 'careedit', 'youse'...  \n",
       "2                  ['bihday', 'yoyouare', 'majesty']  \n",
       "3        ['model', 'love', 'take', 'time', 'youare']  \n",
       "4     ['factsgareinyouide', 'society', 'motivation']  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df = pd.read_csv('./combine_df.csv')\n",
    "combine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49159, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21957    0.0\n",
       "21958    0.0\n",
       "21959    0.0\n",
       "21960    0.0\n",
       "21961    0.0\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = combine_df['label'][:21962]\n",
    "train_y.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21962,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['fatheare', 'dysfyounctional', 'selfish', 'da...\n",
       "1    ['thank', 'foare', 'lyft', 'careedit', 'youse'...\n",
       "2                    ['bihday', 'yoyouare', 'majesty']\n",
       "3          ['model', 'love', 'take', 'time', 'youare']\n",
       "4       ['factsgareinyouide', 'society', 'motivation']\n",
       "Name: tweet_lemmatized, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = combine_df['tweet_lemmatized'][:21962]\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31957    0.0\n",
       "31958    0.0\n",
       "31959    0.0\n",
       "31960    1.0\n",
       "31961    0.0\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_y = combine_df['label'][21962:31962]\n",
    "valid_y.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21962    ['msyou', 'tareonline', 'love', 'tareI', 'seek...\n",
       "21963    ['happen', 'see', 'pearefect', 'example', 'wom...\n",
       "21964    ['hope', 'gareinyouy', 'say', 'come', 'tareyou...\n",
       "21965          ['sex', 'blonde', 'sex', 'faarem', 'women']\n",
       "21966    ['befoaree', 'yoyou', 'maybe', 'still', 'carey...\n",
       "Name: tweet_lemmatized, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x = combine_df['tweet_lemmatized'][21962:31962]\n",
    "valid_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31962    ['styoudiolife', 'aislife', 'areeqyouiarees', ...\n",
       "31963    ['white', 'syoupareemacists', 'want', 'evearey...\n",
       "31964    ['safe', 'ways', 'heal', 'yoyouare', 'acne', '...\n",
       "31965    ['hp', 'see', 'yoyouaresed', 'chilateare', 'dy...\n",
       "31966    ['ared', 'bihday', 'amazingarein', 'hilaareioy...\n",
       "Name: tweet_lemmatized, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = combine_df['tweet_lemmatized'][31962:]\n",
    "test_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17197,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_train = tokenizer.texts_to_sequences(train_x)\n",
    "sequences_val = tokenizer.texts_to_sequences(valid_x)\n",
    "sequences_test = tokenizer.texts_to_sequences(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = len(tokenizer.index_word) + 1\n",
    "training_length = max([len(i.split()) for i in train_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(sequences_train, maxlen=training_length)\n",
    "X_valid = pad_sequences(sequences_val, maxlen=training_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_y\n",
    "y_val = valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(SimpleRNN(64))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================] - 2s 63ms/step - loss: 0.3057 - accuracy: 0.9240 - val_loss: 0.2512 - val_accuracy: 0.9304\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 2s 57ms/step - loss: 0.2577 - accuracy: 0.9308 - val_loss: 0.2414 - val_accuracy: 0.9304\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 2s 55ms/step - loss: 0.1825 - accuracy: 0.9408 - val_loss: 0.1522 - val_accuracy: 0.9508\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 2s 62ms/step - loss: 0.0712 - accuracy: 0.9765 - val_loss: 0.1360 - val_accuracy: 0.9527\n",
      "Epoch 5/10\n",
      "39/39 [==============================] - 2s 60ms/step - loss: 0.0278 - accuracy: 0.9927 - val_loss: 0.1584 - val_accuracy: 0.9481\n"
     ]
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 20ms/step - loss: 0.1542 - accuracy: 0.9552\n",
      "\n",
      "\n",
      "Test score: 0.15423792600631714\n",
      "Test accuracy: 0.9552000164985657\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================] - 5s 136ms/step - loss: 0.4083 - accuracy: 0.9154 - val_loss: 0.2486 - val_accuracy: 0.9304\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 5s 123ms/step - loss: 0.2392 - accuracy: 0.9308 - val_loss: 0.2076 - val_accuracy: 0.9304\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 5s 141ms/step - loss: 0.1428 - accuracy: 0.9471 - val_loss: 0.1342 - val_accuracy: 0.9545\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 5s 125ms/step - loss: 0.0661 - accuracy: 0.9785 - val_loss: 0.1505 - val_accuracy: 0.9586\n"
     ]
    }
   ],
   "source": [
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model_1.add(Masking(mask_value=0.0))\n",
    "model_1.add(LSTM(64, recurrent_dropout=0.2))\n",
    "model_1.add(Dense(64, activation='relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_1.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model_1.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 35ms/step - loss: 0.1531 - accuracy: 0.9555\n",
      "\n",
      "\n",
      "Test score: 0.15307702124118805\n",
      "Test accuracy: 0.9555000066757202\n"
     ]
    }
   ],
   "source": [
    "score = model_1.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "39/39 [==============================] - 5s 117ms/step - loss: 0.4240 - accuracy: 0.9199 - val_loss: 0.2399 - val_accuracy: 0.9304\n",
      "Epoch 2/10\n",
      "39/39 [==============================] - 4s 106ms/step - loss: 0.2011 - accuracy: 0.9323 - val_loss: 0.1745 - val_accuracy: 0.9331\n",
      "Epoch 3/10\n",
      "39/39 [==============================] - 5s 121ms/step - loss: 0.1105 - accuracy: 0.9564 - val_loss: 0.1393 - val_accuracy: 0.9518\n",
      "Epoch 4/10\n",
      "39/39 [==============================] - 4s 107ms/step - loss: 0.0507 - accuracy: 0.9829 - val_loss: 0.1509 - val_accuracy: 0.9558\n"
     ]
    }
   ],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(\n",
    "    Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model_2.add(Masking(mask_value=0.0))\n",
    "model_2.add(GRU(64, recurrent_dropout=0.2))\n",
    "model_2.add(Dense(64, activation='relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_2.compile(\n",
    "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "\n",
    "history = model_2.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 39ms/step - loss: 0.1453 - accuracy: 0.9580\n",
      "\n",
      "\n",
      "Test score: 0.14527447521686554\n",
      "Test accuracy: 0.9580000042915344\n"
     ]
    }
   ],
   "source": [
    "score = model_2.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше всего себя показала последняя модель со слоем GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
