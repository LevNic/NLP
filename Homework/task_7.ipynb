{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import tensorflow.compat.v1 as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(w):\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    w = w.strip()\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.lstm(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.lstm(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        dec_hidden = enc_hidden\n",
    "        dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions)\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    \n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    inputs = [inp_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += targ_lang_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    fontdict = {'fontsize': 14}\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "    #ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    #ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './rus-eng/rus.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(preprocess_sentence(input_text))\n",
    "    target_texts.append(preprocess_sentence(target_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor, inp_lang_tokenizer = tokenize(input_texts)\n",
    "target_tensor, targ_lang_tokenizer = tokenize(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_inp_size = len(inp_lang_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(targ_lang_tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 0.1144\n",
      "Epoch 2 Loss 0.0313\n",
      "Epoch 3 Loss 0.0237\n",
      "Epoch 4 Loss 0.0212\n",
      "Epoch 5 Loss 0.0197\n",
      "Epoch 6 Loss 0.0181\n",
      "Epoch 7 Loss 0.0181\n",
      "Epoch 8 Loss 0.0168\n",
      "Epoch 9 Loss 0.0157\n",
      "Epoch 10 Loss 0.0146\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> go now <end>\n",
      "Predicted translation: . <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate('go now')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## не переводит!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
